{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of artificial (synthetic) patient data\n",
    "\n",
    "Note: This artificial data is intended only for use in exploring the methods, using up to 10 features. The method of synthethis does not maintain any covariance between features (as feature values are created independetly of each other, to eliminate any risk of identifying original data), though average feature values for patients at each hopsital are approximately maintained. These data may be used to train models with minimal loss of accuracy.\n",
    "\n",
    "The key methodology is:\n",
    "\n",
    "* Remove thrombolysis label\n",
    "* Group original data by hopsital\n",
    "    * For each of 10 features take bootstrap samples of that feature\n",
    "* Combine data across hospitals\n",
    "* Remove any duplicate rows, or rows that are identical to original data\n",
    "* Train an XGBoost model on original data to predict use of thrombolysis\n",
    "* Use the XGBoost model to leabl the synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn warnings off to keep notebook tidy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_loc = '../data/samuel_1/10k_training_test/'\n",
    "original_data = pd.read_csv(data_loc + 'cohort_10000_train.csv')\n",
    "\n",
    "# Get stroke teams = \n",
    "stroke_teams = list(set(original_data['StrokeTeam']))\n",
    "stroke_teams.sort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create unlabelled synthetic data by bootstrap sampling from individual feature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = 1000\n",
    "synthetic_data_list = []\n",
    "\n",
    "# Sample data for each stroke team\n",
    "for stroke_team in stroke_teams:\n",
    "    # Set up data frame for synthetic team data\n",
    "    synthetic_data = pd.DataFrame()\n",
    "    \n",
    "    # Get original team data\n",
    "    mask = original_data['StrokeTeam'] == stroke_team\n",
    "    team_data = original_data[mask]\n",
    "    team_data_length = len(team_data)\n",
    "    \n",
    "    # Set team\n",
    "    synthetic_data['StrokeTeam'] = np.repeat(stroke_team, cases)\n",
    "    # Sample individual items from orioginal data with replacement\n",
    "\n",
    "    # Arrival to image time\n",
    "    synthetic_data['S2BrainImagingTime_min'] = np.random.choice(\n",
    "        team_data['S2BrainImagingTime_min'], replace=True, size=cases)\n",
    "    \n",
    "    # Sample features independently from observed values\n",
    "\n",
    "    synthetic_data['S2StrokeType_Infarction'] = np.random.choice(\n",
    "        team_data['S2StrokeType_Infarction'], replace=True, size=cases)\n",
    "\n",
    "    synthetic_data['S2NihssArrival'] = np.random.choice(\n",
    "        team_data['S2NihssArrival'], replace=True, size=cases)\n",
    "    \n",
    "    synthetic_data['S2RankinBeforeStroke'] = np.random.choice(\n",
    "        team_data['S2RankinBeforeStroke'], replace=True, size=cases)\n",
    "    \n",
    "    synthetic_data['AFAnticoagulent_Yes'] = np.random.choice(\n",
    "        team_data['AFAnticoagulent_Yes'], replace=True, size=cases)\n",
    "\n",
    "    synthetic_data['S1OnsetToArrival_min'] = np.random.choice(\n",
    "        team_data['S1OnsetToArrival_min'], replace=True, size=cases)\n",
    "    \n",
    "    synthetic_data['S1AgeOnArrival'] = np.random.choice(\n",
    "        team_data['S1AgeOnArrival'], replace=True, size=cases)\n",
    "    \n",
    "    # Use the same random index for S1OnsetTimeType_Precise and S1OnsetDateType_Stroke\n",
    "    random_index = np.random.randint(0, team_data_length, size=cases)\n",
    "\n",
    "    synthetic_data['S1OnsetTimeType_Precise'] = \\\n",
    "            [team_data['S1OnsetTimeType_Precise'].iloc[i] for i in random_index]\n",
    "    \n",
    "    synthetic_data['S1OnsetDateType_Stroke during sleep'] = \\\n",
    "            [team_data['S1OnsetDateType_Stroke during sleep'].iloc[i] for i in random_index]    \n",
    "\n",
    "    # Add team data to full synthetic data\n",
    "    synthetic_data_list.append(synthetic_data)\n",
    "\n",
    "# Concatenate lists\n",
    "synthetic_data_df = pd.concat(synthetic_data_list)\n",
    "\n",
    "# Shuffle data\n",
    "synthetic_data_df = synthetic_data_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_time = 106\n",
    "image_time = int((image_time + 5)/ 10) * 10\n",
    "image_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model on original data, to use to label synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.848\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train = pd.read_csv(data_loc + 'cohort_10000_train.csv')\n",
    "test = pd.read_csv(data_loc + 'cohort_10000_test.csv')\n",
    "\n",
    "# Read in the names of the selected features for the model\n",
    "number_of_features_to_use = 10\n",
    "key_features = pd.read_csv('../data/samuel_1/feature_selection.csv')\n",
    "key_features = list(key_features['feature'])[:number_of_features_to_use]\n",
    "# And add the target feature name: S2Thrombolysis\n",
    "key_features.append(\"S2Thrombolysis\")\n",
    "\n",
    "# Select features\n",
    "train = train[key_features]\n",
    "test = test[key_features]\n",
    "\n",
    "# Get X and y\n",
    "X_train = train.drop('S2Thrombolysis', axis=1)\n",
    "X_test = test.drop('S2Thrombolysis', axis=1)\n",
    "y_train = train['S2Thrombolysis']\n",
    "y_test = test['S2Thrombolysis']\n",
    "\n",
    "# One hot encode hospitals\n",
    "X_train_hosp = pd.get_dummies(X_train['StrokeTeam'], prefix = 'team')\n",
    "X_train = pd.concat([X_train, X_train_hosp], axis=1)\n",
    "X_train.drop('StrokeTeam', axis=1, inplace=True)\n",
    "X_test_hosp = pd.get_dummies(X_test['StrokeTeam'], prefix = 'team')\n",
    "X_test = pd.concat([X_test, X_test_hosp], axis=1)\n",
    "X_test.drop('StrokeTeam', axis=1, inplace=True)    \n",
    "\n",
    "# Define model\n",
    "model = XGBClassifier(verbosity=0, seed=42, learning_rate=0.5)\n",
    "\n",
    "# Fit model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get predicted probabilities and class\n",
    "y_probs = model.predict_proba(X_test)[:,1]\n",
    "y_pred = y_probs > 0.5\n",
    "\n",
    "# Show accuracy\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print (f'Accuracy: {accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict label for synthetic data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode hopsitals\n",
    "X_features = key_features.copy(); X_features.remove('S2Thrombolysis')\n",
    "X_synthetic = synthetic_data_df[X_features]\n",
    "X_synthetic_hosp = pd.get_dummies(X_synthetic['StrokeTeam'], prefix = 'team')\n",
    "X_synthetic = pd.concat([X_synthetic, X_synthetic_hosp], axis=1)\n",
    "X_synthetic.drop('StrokeTeam', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities and class\n",
    "y_probs = model.predict_proba(X_synthetic)[:,1]\n",
    "y_pred = np.array([np.random.binomial(1, p) for p in y_probs])\n",
    "\n",
    "# Ensure non-iscaemica stroke have no thrombolysis\n",
    "mask = synthetic_data_df['S2StrokeType_Infarction'] == 0\n",
    "y_pred[mask] = 0\n",
    "\n",
    "synthetic_data_df['S2Thrombolysis'] = y_pred\n",
    "# Save\n",
    "synthetic_data_df.to_csv('./output/synthetic_10K_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StrokeTeam</th>\n",
       "      <th>S2BrainImagingTime_min</th>\n",
       "      <th>S2StrokeType_Infarction</th>\n",
       "      <th>S2NihssArrival</th>\n",
       "      <th>S2RankinBeforeStroke</th>\n",
       "      <th>AFAnticoagulent_Yes</th>\n",
       "      <th>S1OnsetToArrival_min</th>\n",
       "      <th>S1AgeOnArrival</th>\n",
       "      <th>S1OnsetTimeType_Precise</th>\n",
       "      <th>S1OnsetDateType_Stroke during sleep</th>\n",
       "      <th>S2Thrombolysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>UIWEN7236N</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>96.0</td>\n",
       "      <td>72.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>LFZMO6561M</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>77.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>SBYTE4026H</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>47.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>QNARI2373R</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>GLRVJ5773V</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>PSNKC7508G</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>72.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>IWINL6248B</td>\n",
       "      <td>1619.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>52.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>QNARI2373R</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>97.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>TBZOA3799I</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>KZKEZ2257Z</td>\n",
       "      <td>159.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     StrokeTeam  S2BrainImagingTime_min  S2StrokeType_Infarction  \\\n",
       "403  UIWEN7236N                    58.0                        1   \n",
       "611  LFZMO6561M                    15.0                        1   \n",
       "543  SBYTE4026H                    93.0                        1   \n",
       "569  QNARI2373R                    32.0                        1   \n",
       "971  GLRVJ5773V                    28.0                        1   \n",
       "..          ...                     ...                      ...   \n",
       "251  PSNKC7508G                    24.0                        1   \n",
       "643  IWINL6248B                  1619.0                        1   \n",
       "40   QNARI2373R                    40.0                        1   \n",
       "188  TBZOA3799I                    10.0                        1   \n",
       "197  KZKEZ2257Z                   159.0                        1   \n",
       "\n",
       "     S2NihssArrival  S2RankinBeforeStroke  AFAnticoagulent_Yes  \\\n",
       "403             2.0                     0                    1   \n",
       "611             2.0                     3                    0   \n",
       "543            28.0                     1                    0   \n",
       "569             4.0                     3                    0   \n",
       "971             4.0                     0                    0   \n",
       "..              ...                   ...                  ...   \n",
       "251             5.0                     1                    1   \n",
       "643             2.0                     5                    0   \n",
       "40             11.0                     1                    0   \n",
       "188             2.0                     5                    0   \n",
       "197             8.0                     3                    0   \n",
       "\n",
       "     S1OnsetToArrival_min  S1AgeOnArrival  S1OnsetTimeType_Precise  \\\n",
       "403                  96.0            72.5                        1   \n",
       "611                 134.0            77.5                        1   \n",
       "543                  79.0            47.5                        1   \n",
       "569                  29.0            87.5                        1   \n",
       "971                  79.0            87.5                        1   \n",
       "..                    ...             ...                      ...   \n",
       "251                  60.0            72.5                        1   \n",
       "643                 123.0            52.5                        0   \n",
       "40                   73.0            97.5                        1   \n",
       "188                 210.0            82.5                        1   \n",
       "197                 131.0            42.5                        0   \n",
       "\n",
       "     S1OnsetDateType_Stroke during sleep  S2Thrombolysis  \n",
       "403                                    0               0  \n",
       "611                                    0               0  \n",
       "543                                    0               0  \n",
       "569                                    0               1  \n",
       "971                                    0               1  \n",
       "..                                   ...             ...  \n",
       "251                                    0               0  \n",
       "643                                    0               0  \n",
       "40                                     0               0  \n",
       "188                                    0               0  \n",
       "197                                    0               0  \n",
       "\n",
       "[132000 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test synthetic data to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.844\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train = synthetic_data_df\n",
    "test = pd.read_csv(data_loc + 'cohort_10000_test.csv')\n",
    "\n",
    "# Select features\n",
    "train = train[key_features]\n",
    "test = test[key_features]\n",
    "\n",
    "# Get X and y\n",
    "X_train = train.drop('S2Thrombolysis', axis=1)\n",
    "X_test = test.drop('S2Thrombolysis', axis=1)\n",
    "y_train = train['S2Thrombolysis']\n",
    "y_test = test['S2Thrombolysis']\n",
    "\n",
    "# One hot encode hospitals\n",
    "X_train_hosp = pd.get_dummies(X_train['StrokeTeam'], prefix = 'team')\n",
    "X_train = pd.concat([X_train, X_train_hosp], axis=1)\n",
    "X_train.drop('StrokeTeam', axis=1, inplace=True)\n",
    "X_test_hosp = pd.get_dummies(X_test['StrokeTeam'], prefix = 'team')\n",
    "X_test = pd.concat([X_test, X_test_hosp], axis=1)\n",
    "X_test.drop('StrokeTeam', axis=1, inplace=True)    \n",
    "\n",
    "# Define model\n",
    "model = XGBClassifier(verbosity=0, seed=42, learning_rate=0.5)\n",
    "\n",
    "# Fit model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get predicted probabilities and class\n",
    "y_probs = model.predict_proba(X_test)[:,1]\n",
    "y_pred = y_probs > 0.5\n",
    "\n",
    "# Show accuracy\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print (f'Accuracy: {accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ROC here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine distances between synthetic-real and real-real near neighbours\n",
    "\n",
    "Distance are Cartesian distance between standardised data points."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to standardise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise_data(X_train, X_test):\n",
    "    \n",
    "    # Initialise a new scaling object for normalising input data\n",
    "    sc = StandardScaler() \n",
    "\n",
    "    # Set up the scaler just on the training set\n",
    "    sc.fit(X_train)\n",
    "\n",
    "    # Apply the scaler to the training and test sets\n",
    "    train_std=sc.transform(X_train)\n",
    "    test_std=sc.transform(X_test)\n",
    "    \n",
    "    return train_std, test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up lists to store results\n",
    "all_dist_real_real = []\n",
    "all_dist_real_synthetic = []\n",
    "\n",
    "for stroke_team in stroke_teams:\n",
    "\n",
    "    # Get original team data\n",
    "    mask = original_data['StrokeTeam'] == stroke_team\n",
    "    team_original = original_data[mask][key_features]\n",
    "    team_original.drop(['StrokeTeam', 'S2Thrombolysis'], axis=1, inplace=True)\n",
    "    original_size = len(team_original)\n",
    "\n",
    "    # Get synthetic data (match sample size to orginal data)\n",
    "    mask = synthetic_data_df['StrokeTeam'] == stroke_team\n",
    "    team_synthetic = synthetic_data_df[mask][key_features]\n",
    "    team_synthetic.drop(['StrokeTeam', 'S2Thrombolysis'], axis=1, inplace=True)\n",
    "    synthetic_size = len(team_synthetic)\n",
    "\n",
    "    # Reduce larger set to size of small set\n",
    "    if synthetic_size > original_size:\n",
    "        team_synthetic = team_synthetic.sample(original_size)\n",
    "    else:\n",
    "        team_original = team_original.sample(synthetic_size)\n",
    "\n",
    "    # Standardise\n",
    "    team_original_std, team_synthetic_std = standardise_data(\n",
    "        team_original, team_synthetic)\n",
    "\n",
    "    # Get nearest neighbour distances in real data\n",
    "    nn = NearestNeighbors(n_neighbors=1, algorithm='auto').fit(team_original_std)\n",
    "    dists, idxs = nn.kneighbors()\n",
    "    dist_real_real = dists.flatten()\n",
    "    all_dist_real_real.append(dist_real_real)\n",
    "\n",
    "    # Get closest real data point to synthetic data points\n",
    "    dists, idxs = nn.kneighbors(team_synthetic_std)\n",
    "    dist_real_synthetic = dists.flatten()\n",
    "    all_dist_real_synthetic.append(dist_real_synthetic)\n",
    "\n",
    "# Concatenate all distances\n",
    "all_dist_real_real = np.concatenate(np.array(all_dist_real_real))\n",
    "all_dist_real_synthetic = np.concatenate(np.array(all_dist_real_synthetic))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('samuel')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b368e36a85415766688ec72e3e874a4b525584eabf4bf7122952a4e0fd64fcde"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
