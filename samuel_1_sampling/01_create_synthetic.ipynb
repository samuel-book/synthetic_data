{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of artificial (synthetic) patient data\n",
    "\n",
    "Note: This artificial data is intended only for use in exploring the methods, using up to 10 features. The method of synthethis does not maintain any covariance between features (as feature values are created independetly of each other, to eliminate any risk of identifying original data), though average feature values for patients at each hopsital are approximately maintained. These data may be used to train models with minimal loss of accuracy.\n",
    "\n",
    "The key methodology is:\n",
    "\n",
    "* Remove thrombolysis label\n",
    "* Group original data by hopsital\n",
    "    * For each of 10 features take bootstrap samples of that feature\n",
    "* Combine data across hospitals\n",
    "* Remove any duplicate rows, or rows that are identical to original data\n",
    "* Train an XGBoost model on original data to predict use of thrombolysis\n",
    "* Use the XGBoost model to leabl the synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn warnings off to keep notebook tidy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_loc = '../data/samuel_1/10k_training_test/'\n",
    "original_data = pd.read_csv(data_loc + 'cohort_10000_train.csv')\n",
    "\n",
    "# Get stroke teams = \n",
    "stroke_teams = list(set(original_data['StrokeTeam']))\n",
    "stroke_teams.sort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create unlabelled synthetic data by bootstrap sampling from individual feature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = 1000\n",
    "synthetic_data_list = []\n",
    "\n",
    "# Sample data for each stroke team\n",
    "for stroke_team in stroke_teams:\n",
    "    # Set up data frame for synthetic team data\n",
    "    synthetic_data = pd.DataFrame()\n",
    "    \n",
    "    # Get original team data\n",
    "    mask = original_data['StrokeTeam'] == stroke_team\n",
    "    team_data = original_data[mask]\n",
    "    team_data_length = len(team_data)\n",
    "    \n",
    "    # Set team\n",
    "    synthetic_data['StrokeTeam'] = np.repeat(stroke_team, cases)\n",
    "    # Sample individual items from orioginal data with replacement\n",
    "\n",
    "    synthetic_data['S2BrainImagingTime_min'] = np.random.choice(\n",
    "        team_data['S2BrainImagingTime_min'], replace=True, size=cases)\n",
    "\n",
    "    synthetic_data['S2StrokeType_Infarction'] = np.random.choice(\n",
    "        team_data['S2StrokeType_Infarction'], replace=True, size=cases)\n",
    "\n",
    "    synthetic_data['S2NihssArrival'] = np.random.choice(\n",
    "        team_data['S2NihssArrival'], replace=True, size=cases)\n",
    "    \n",
    "    synthetic_data['S2RankinBeforeStroke'] = np.random.choice(\n",
    "        team_data['S2RankinBeforeStroke'], replace=True, size=cases)\n",
    "    \n",
    "    synthetic_data['AFAnticoagulent_Yes'] = np.random.choice(\n",
    "        team_data['AFAnticoagulent_Yes'], replace=True, size=cases)\n",
    "\n",
    "    synthetic_data['S1OnsetToArrival_min'] = np.random.choice(\n",
    "        team_data['S1OnsetToArrival_min'], replace=True, size=cases)\n",
    "    \n",
    "    synthetic_data['S1AgeOnArrival'] = np.random.choice(\n",
    "        team_data['S1AgeOnArrival'], replace=True, size=cases)\n",
    "    \n",
    "    # Use the same random index for S1OnsetTimeType_Precise and S1OnsetDateType_Stroke\n",
    "    random_index = np.random.randint(0, team_data_length, size=cases)\n",
    "\n",
    "    synthetic_data['S1OnsetTimeType_Precise'] = \\\n",
    "            [team_data['S1OnsetTimeType_Precise'].iloc[i] for i in random_index]\n",
    "    \n",
    "    synthetic_data['S1OnsetDateType_Stroke during sleep'] = \\\n",
    "            [team_data['S1OnsetDateType_Stroke during sleep'].iloc[i] for i in random_index]    \n",
    "\n",
    "    synthetic_data_list.append(synthetic_data)\n",
    "\n",
    "# Concatenate lists\n",
    "synthetic_data_df = pd.concat(synthetic_data_list)\n",
    "\n",
    "# Shuffle data\n",
    "synthetic_data_df = synthetic_data_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model on original data, to use to label synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.848\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train = pd.read_csv(data_loc + 'cohort_10000_train.csv')\n",
    "test = pd.read_csv(data_loc + 'cohort_10000_test.csv')\n",
    "\n",
    "# Read in the names of the selected features for the model\n",
    "number_of_features_to_use = 10\n",
    "key_features = pd.read_csv('../data/samuel_1/feature_selection.csv')\n",
    "key_features = list(key_features['feature'])[:number_of_features_to_use]\n",
    "# And add the target feature name: S2Thrombolysis\n",
    "key_features.append(\"S2Thrombolysis\")\n",
    "\n",
    "# Select features\n",
    "train = train[key_features]\n",
    "test = test[key_features]\n",
    "\n",
    "# Get X and y\n",
    "X_train = train.drop('S2Thrombolysis', axis=1)\n",
    "X_test = test.drop('S2Thrombolysis', axis=1)\n",
    "y_train = train['S2Thrombolysis']\n",
    "y_test = test['S2Thrombolysis']\n",
    "\n",
    "# One hot encode hospitals\n",
    "X_train_hosp = pd.get_dummies(X_train['StrokeTeam'], prefix = 'team')\n",
    "X_train = pd.concat([X_train, X_train_hosp], axis=1)\n",
    "X_train.drop('StrokeTeam', axis=1, inplace=True)\n",
    "X_test_hosp = pd.get_dummies(X_test['StrokeTeam'], prefix = 'team')\n",
    "X_test = pd.concat([X_test, X_test_hosp], axis=1)\n",
    "X_test.drop('StrokeTeam', axis=1, inplace=True)    \n",
    "\n",
    "# Define model\n",
    "model = XGBClassifier(verbosity=0, seed=42, learning_rate=0.5)\n",
    "\n",
    "# Fit model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get predicted probabilities and class\n",
    "y_probs = model.predict_proba(X_test)[:,1]\n",
    "y_pred = y_probs > 0.5\n",
    "\n",
    "# Show accuracy\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print (f'Accuracy: {accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict label for synthetic data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode hopsitals\n",
    "X_features = key_features.copy(); X_features.remove('S2Thrombolysis')\n",
    "X_synthetic = synthetic_data_df[X_features]\n",
    "X_synthetic_hosp = pd.get_dummies(X_synthetic['StrokeTeam'], prefix = 'team')\n",
    "X_synthetic = pd.concat([X_synthetic, X_synthetic_hosp], axis=1)\n",
    "X_synthetic.drop('StrokeTeam', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities and class\n",
    "y_probs = model.predict_proba(X_synthetic)[:,1]\n",
    "y_pred = np.array([np.random.binomial(1, p) for p in y_probs])\n",
    "\n",
    "# Ensure non-iscaemica stroke have no thrombolysis\n",
    "mask = synthetic_data_df['S2StrokeType_Infarction'] == 0\n",
    "y_pred[mask] = 0\n",
    "\n",
    "synthetic_data_df['S2Thrombolysis'] = y_pred\n",
    "# Save\n",
    "synthetic_data_df.to_csv('./output/synthetic_10K_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StrokeTeam</th>\n",
       "      <th>S2BrainImagingTime_min</th>\n",
       "      <th>S2StrokeType_Infarction</th>\n",
       "      <th>S2NihssArrival</th>\n",
       "      <th>S2RankinBeforeStroke</th>\n",
       "      <th>AFAnticoagulent_Yes</th>\n",
       "      <th>S1OnsetToArrival_min</th>\n",
       "      <th>S1AgeOnArrival</th>\n",
       "      <th>S1OnsetTimeType_Precise</th>\n",
       "      <th>S1OnsetDateType_Stroke during sleep</th>\n",
       "      <th>S2Thrombolysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>WKDIW7014B</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>135.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>KZKEZ2257Z</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>UJETD9177J</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>77.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>TQQYU0036V</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>67.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>ROOIZ9592Y</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>92.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>FLVXS2956M</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>KZKEZ2257Z</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>67.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>YQMZV4284N</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>72.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>DLNBB9786K</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>92.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>GLRVJ5773V</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>97.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     StrokeTeam  S2BrainImagingTime_min  S2StrokeType_Infarction  \\\n",
       "910  WKDIW7014B                   221.0                        1   \n",
       "563  KZKEZ2257Z                    21.0                        1   \n",
       "387  UJETD9177J                    13.0                        1   \n",
       "225  TQQYU0036V                    13.0                        1   \n",
       "843  ROOIZ9592Y                    23.0                        1   \n",
       "..          ...                     ...                      ...   \n",
       "842  FLVXS2956M                     5.0                        1   \n",
       "316  KZKEZ2257Z                    42.0                        1   \n",
       "427  YQMZV4284N                    48.0                        1   \n",
       "228  DLNBB9786K                    17.0                        0   \n",
       "973  GLRVJ5773V                     9.0                        1   \n",
       "\n",
       "     S2NihssArrival  S2RankinBeforeStroke  AFAnticoagulent_Yes  \\\n",
       "910             0.0                     2                    1   \n",
       "563             2.0                     5                    0   \n",
       "387            19.0                     4                    0   \n",
       "225             2.0                     0                    0   \n",
       "843            10.0                     3                    0   \n",
       "..              ...                   ...                  ...   \n",
       "842            10.0                     4                    0   \n",
       "316             5.0                     3                    0   \n",
       "427             4.0                     0                    0   \n",
       "228            17.0                     4                    0   \n",
       "973            10.0                     0                    0   \n",
       "\n",
       "     S1OnsetToArrival_min  S1AgeOnArrival  S1OnsetTimeType_Precise  \\\n",
       "910                 135.0            82.5                        1   \n",
       "563                  83.0            82.5                        1   \n",
       "387                  79.0            77.5                        0   \n",
       "225                 127.0            67.5                        1   \n",
       "843                 195.0            92.5                        1   \n",
       "..                    ...             ...                      ...   \n",
       "842                  44.0            72.5                        0   \n",
       "316                 163.0            67.5                        1   \n",
       "427                  92.0            72.5                        0   \n",
       "228                 109.0            92.5                        0   \n",
       "973                  58.0            97.5                        1   \n",
       "\n",
       "     S1OnsetDateType_Stroke during sleep  S2Thrombolysis  \n",
       "910                                    0               0  \n",
       "563                                    0               0  \n",
       "387                                    0               0  \n",
       "225                                    0               0  \n",
       "843                                    0               0  \n",
       "..                                   ...             ...  \n",
       "842                                    0               0  \n",
       "316                                    0               1  \n",
       "427                                    1               0  \n",
       "228                                    0               0  \n",
       "973                                    0               1  \n",
       "\n",
       "[132000 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test synthetic data to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.847\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train = synthetic_data_df\n",
    "test = pd.read_csv(data_loc + 'cohort_10000_test.csv')\n",
    "\n",
    "# Select features\n",
    "train = train[key_features]\n",
    "test = test[key_features]\n",
    "\n",
    "# Get X and y\n",
    "X_train = train.drop('S2Thrombolysis', axis=1)\n",
    "X_test = test.drop('S2Thrombolysis', axis=1)\n",
    "y_train = train['S2Thrombolysis']\n",
    "y_test = test['S2Thrombolysis']\n",
    "\n",
    "# One hot encode hospitals\n",
    "X_train_hosp = pd.get_dummies(X_train['StrokeTeam'], prefix = 'team')\n",
    "X_train = pd.concat([X_train, X_train_hosp], axis=1)\n",
    "X_train.drop('StrokeTeam', axis=1, inplace=True)\n",
    "X_test_hosp = pd.get_dummies(X_test['StrokeTeam'], prefix = 'team')\n",
    "X_test = pd.concat([X_test, X_test_hosp], axis=1)\n",
    "X_test.drop('StrokeTeam', axis=1, inplace=True)    \n",
    "\n",
    "# Define model\n",
    "model = XGBClassifier(verbosity=0, seed=42, learning_rate=0.5)\n",
    "\n",
    "# Fit model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get predicted probabilities and class\n",
    "y_probs = model.predict_proba(X_test)[:,1]\n",
    "y_pred = y_probs > 0.5\n",
    "\n",
    "# Show accuracy\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print (f'Accuracy: {accuracy:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('samuel')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b368e36a85415766688ec72e3e874a4b525584eabf4bf7122952a4e0fd64fcde"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
